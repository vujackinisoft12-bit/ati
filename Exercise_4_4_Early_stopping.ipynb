{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4.4 Early stopping"
      ],
      "metadata": {
        "id": "ApEGsGnec6BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will use the same titanic dataset from the previous exercises. You can download the dataset from the following link:\n",
        "\n",
        "[titanic_all_numeric.csv](https://drive.google.com/file/d/11nuYS-l3EXCsGJt81y4YTt3oTnFGaB68/view?usp=drive_link)\n",
        "\n",
        "The data is pre-loaded into a pandas DataFrame called `df`. The `predictors` and `target` values are also pre-defined.\n",
        "\n",
        "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more.\n",
        "\n",
        "Since the optimization stops automatically when it isn't helping, you can also set a high value for `epochs` in your call to `model.fit()`, as shown in the video."
      ],
      "metadata": {
        "id": "mEOOH6NdV42q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions"
      ],
      "metadata": {
        "id": "-AWPd5Wqft_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import EarlyStopping from `tensorflow.keras.callbacks`.\n",
        "* Compile the model, once again using `'adam'` as the optimizer, `'categorical_crossentropy'` as the loss function, and `metrics=['accuracy']` to see the accuracy at each epoch.\n",
        "* Create an `EarlyStopping` object called `early_stopping_monitor`. Stop optimization when the validation loss hasn't improved for `2` epochs by specifying the `patience` parameter of `EarlyStopping()` to be `2`.\n",
        "* Fit the model using the `predictors` and `target`. Specify the number of `epochs` to be `30` and use a validation split of `0.3`. In addition, pass `[early_stopping_monitor]` to the `callbacks` parameter."
      ],
      "metadata": {
        "id": "fNotC4abWBqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "oKx-pAyrlVGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and convert the data to NumPy array:"
      ],
      "metadata": {
        "id": "K2uQ5t2BRtpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dlu9wWcWcy44",
        "outputId": "d852c7d3-a6c4-42ea-d402-26db171cd477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2055442983.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Load csv file into the dataframe: df\n",
        "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
        "\n",
        "# Convert the boolean values of the 'age_was_missing' column to integer\n",
        "df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
        "\n",
        "# Create predictors NumPy array: predictors\n",
        "predictors = df.drop(['survived'], axis=1).values\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(df['survived'])\n",
        "\n",
        "# Define the input shape: input_shape\n",
        "input_shape = (n_cols,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a neural network for a classification task"
      ],
      "metadata": {
        "id": "9jf6A0pPsATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def get_new_model(input_shape):\n",
        "  # Set up the model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "wkgdNpMmsKmt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and fit the model with a validation dataset:"
      ],
      "metadata": {
        "id": "u986qJ_NOK1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Specify the model\n",
        "model = get_new_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(predictors,\n",
        "                 target,\n",
        "                 validation_split=0.3,\n",
        "                 epochs=30,\n",
        "                 callbacks=[early_stopping_monitor],\n",
        "                 verbose=1)\n"
      ],
      "metadata": {
        "id": "rdrPE2NrOjS5",
        "outputId": "ba7aa245-39ef-4d52-8a38-57d8222f34f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5507 - loss: 1.1765 - val_accuracy: 0.6418 - val_loss: 0.9189\n",
            "Epoch 2/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5858 - loss: 0.8789 - val_accuracy: 0.7201 - val_loss: 0.5757\n",
            "Epoch 3/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6240 - loss: 0.6714 - val_accuracy: 0.6903 - val_loss: 0.5854\n",
            "Epoch 4/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6502 - loss: 0.6588 - val_accuracy: 0.7276 - val_loss: 0.6155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ouput should be:\n",
        "\n",
        "Epoch 1/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 2s 13ms/step - accuracy: 0.5731 - loss: 1.1071 - val_accuracy: 0.6418 - val_loss: 0.9236\n",
        "\n",
        "Epoch 2/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6097 - loss: 0.9196 - val_accuracy: 0.7052 - val_loss: 0.6230\n",
        "\n",
        "Epoch 3/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6948 - loss: 0.6637 - val_accuracy: 0.7388 - val_loss: 0.5652\n",
        "\n",
        "Epoch 4/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6990 - loss: 0.5773 - val_accuracy: 0.7575 - val_loss: 0.5165\n",
        "\n",
        "Epoch 5/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6590 - loss: 0.6028 - val_accuracy: 0.7388 - val_loss: 0.5050\n",
        "\n",
        "Epoch 6/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7085 - loss: 0.5905 - val_accuracy: 0.7500 - val_loss: 0.4878\n",
        "\n",
        "Epoch 7/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7205 - loss: 0.5815 - val_accuracy: 0.7537 - val_loss: 0.4762\n",
        "\n",
        "Epoch 8/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7112 - loss: 0.5816 - val_accuracy: 0.6754 - val_loss: 0.7343\n",
        "\n",
        "Epoch 9/30\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6515 - loss: 0.7081 - val_accuracy: 0.7799 - val_loss: 0.5372\n"
      ],
      "metadata": {
        "id": "ecubSk7GZKKp"
      }
    }
  ]
}